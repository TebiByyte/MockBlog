<!DOCTYPE html>
<html>
    <head>
        <title>Tech Space Blog</title>
        <link rel="preconnect" href="https://fonts.googleapis.com">
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link href="https://fonts.googleapis.com/css2?family=Inter:ital,opsz,wght@0,14..32,100..900;1,14..32,100..900&family=Istok+Web:ital,wght@0,400;0,700;1,400;1,700&display=swap" rel="stylesheet">
        <link rel="stylesheet" href="styles/style.css">
    </head>
    <body>
        <div class="header-container">
            <p class="blog-title">Tech Space</p>
            <div class="buttons-container">
                <span class="about-me-button">About me</span>
                <div class="buttons-separator"></div>
                <span class="more-button">More</span>
            </div>
        </div>
        <div class="article-header">
            <div class="title-container">
                <h1 class="article-title">Why AI as we know it is unethical</h1>
                <p class="article-title-cont">(and how we can fix it)</p>
                <hr>
            </div>
            <div class="article-info-container">
                <p class="author-name">By Asher Bearce</p>
                <p class="article-date">04/21/2025</p>
            </div>
        </div>
        <article>
            <section class="section">
                <h1 class="section-title">Introduction</h1>
                <p class="section-text">
                    Generative AI is one of the most influential inventions within the last couple of years. AI generated content is everywhere you look on the Internet, from art, to music, to even code, it is everywhere. But, with the invention of AI there are some massive ethical considerations that go ignored by the average user, and the companies that train the AI models themselves. These ethical concerns are becoming more and more important. <a href="https://doi.org/10.17705/1CAIS.05601">In a study by Joakim Laine, et al.</a>, they found increased attention towards questions of non-maleficence and privacy regarding generative AI. All that to say, people are growing more and more concerned with AI being used for malicious purposes and threats to their privacy.
                </p>
            </section>
            <section class="section">
                <h1 class="section-title">The Problem of Data</h1>
                <p class="section-text">
                    AI needs a massive amount of data in order to train. AI “learns” in a way that’s analogous to the way we as humans learn, by analyzing a metric ton of data and looking for patterns. That begs the question, where does all that data come from? The unfortunate answer to that is that it is almost entirely scraped off the Internet, and in some instances, pirated. Scraping is a process by which an automated process downloads content such as images or music off a webpage. This is problematic in two ways. Firstly, using a work for commercial purposes or financial gain without permission is copyright infringement and theft. Secondly, there are some truly horrific things that get posted to the Internet in every form. That content ends up in AI datasets, and the model gets trained off of that content. <a href="https://arxiv.org/pdf/2110.01963.pdf">In a study by Kahembwe, Emmanuel, et al.</a>, they looked at what kinds of content, specifically imagery, can be found inside AI training datasets. What they found was, as the title of the paper suggests, pretty horrifying. AI can only really replicate what it has seen before, so the addition of that kind of content into a dataset means the AI model can reproduce that kind of graphic content. One of the big concerns with that is the ability to create revenge porn with minimal effort, and a picture of someone’s face. Being able to generate that kind of content en masse is frankly terrifying. 
                </p>
                <p class="section-text">
                    Not only is scraping content off the Internet not ideal in the sense that it teaches AI how to generate malicious content, it is also theft and copyright infringement in many cases. Meta is currently facing a class action lawsuit for pirating nearly 82 Terabytes of books just for AI training in secret. That is an absolutely unfathomable amount of stolen books, easily within the multi-millions of books. The keyword is “piracy”. None of those books were obtained by legal means, no author was compensated for their work. However it isn’t just authors that this kind of thing happens to, it happens to artists of all kinds. It has gotten so bad that a researcher developed a tool called Nightshade, that alters digital artwork to essentially poison the work that was scraped off the Internet, so that the AI model interprets the image to be something totally different than what’s depicted. The lengths that artists and creative people have to go through in order to protect their hard work is absurd.
                </p>
            </section>
            <div class="image-card">
                <img src="assets/images/nightshade.png">
                <p class="image-card-text">A diagram showing the effects of Nightshade, a tool created to help artists protect their work. <a href="https://arxiv.org/pdf/2310.13828">(Taken from the research paper here)</a></p>
            </div>
            <section>
                <h1 class="section-title">The Problem With Users</h1>
                <p class="section-text">
                    Another side effect of the lack of ethics surrounding AI is that it can be really easy to use for malicious purposes. Spreading misinformation is a huge problem since it is so easy to create with AI tools. Now with just a few keystrokes and the click of a button, you can generate an entire fake news story about whatever you want. There have been many many examples of politicians using AI imagery to smear their opponents. And while it doesn’t seem bad to those of us that can spot AI fakery, people who aren’t so tech savvy are vulnerable to this kind of manipulation. Not only that, but generative AI is constantly evolving and improving, it’s getting harder and harder to tell what’s AI and what’s not. You can generate very realistic looking images with just a click and a few keystrokes. 
                </p>
                <p class="section-text">
                    Apart from misinformation, there is yet another problem that AI presents us with. When you can generate works of art or music with the click of a button, why even hire an artist? Artists are expensive and it takes time to produce something of quality, but AI only takes a few seconds and at fractions of the cost. Around December of 2024, Coca Cola rolled out an entirely AI generated advertisement that actually aired, and it was received very poorly, sporting about nine thousand likes to about 162,000 dislikes. How many jobs were turned into just a single prompt? How many people didn’t have the opportunity to earn a wage on a commercial project? In addition, Meta has stated many times that they want to replace all their software engineers with generative AI. It’s debatable whether or not that will happen, but the prospect is certainly terrifying for a lot of engineers and artists alike, and it has certainly cost people their jobs. So, essentially yet another way AI can and has been used in a way that is blatantly unethical is by automating jobs that should not be automated. Human creativity should be augmented by AI tools, not replaced completely.
                </p>
            </section>
            <div class="image-card">
                <iframe src="https://www.youtube.com/embed/4RSTupbfGog"></iframe>
                <p class="image-card-text">The entirely AI generated Coca Cola ad, released around December 2024.</p>
            </div>
            <section>
                <h1 class="section-title">So... What Now?</h1>
                <p class="section-text">
                    While it’s easy to use AI in a way that isn’t ethical, that doesn’t mean it isn’t worth having. There’s a reason why generative AI is receiving so much attention. These tools are extremely powerful, and very useful. AI models are the driving force behind things like computer vision and voice controls for something like a smartphone, algorithms that are nigh impossible with traditional programming methods. And those aren’t just a luxury, they can provide essential accessibility features for people who are disabled. So how can things be kept fair for everyone? <a href="http://www.jstor.org/stable/j.ctv26qjjhj.9">A book by Angela Daly</a> proposes a solution, “Good Data”. Good Data proposes a framework for data sourcing for the purposes of training generative AI, and it is focused around community driven contribution to datasets. It is an effective solution to the problems with scraping data off the internet, because artists get to choose if they want to contribute and get compensated for their work, and companies gain more control over what data is in a dataset, and consequently what can be generated with their AI model. It’s a win-win.
                </p>
                <p class="section-text">
                    AI is a tool, and like any tool, it can be misused. It is up to the users and the developers of generative AI models to make it harder to use by bad actors, and make sure they aren’t doing more harm than good. Companies should implement community driven programs as Good Data proposes, to avoid both copyright infringement and to filter out unwanted content from datasets. Furthermore, companies should choose to use AI generated works sparingly, or as an addition to the creative process in any field instead of trying to replace workers entirely. 
                </p>
            </section>
            <section>
                <h1 class="section-title">Works Cited</h1>
                <p class="section-text">Daly, Angela, et al. “AI Ethics Needs Good Data.” AI for Everyone?: Critical Perspectives, edited by Pieter Verdegem, University of Westminster Press, 2021, pp. 103–22. JSTOR, <a href="http://www.jstor.org/stable/j.ctv26qjjhj.9">http://www.jstor.org/stable/j.ctv26qjjhj.9</a>.</p>
                <p class="section-text">Kahembwe, Emmanuel, et al. “Multimodal Datasets: Misogyny, Pornography, and Malignant Stereotypes.” Arxiv.Org, 5 Oct. 2021, <a href="arxiv.org/pdf/2110.01963.pdf">arxiv.org/pdf/2110.01963.pdf</a>.</p>
                <p class="section-text">Laine, Joakim, et al. “Understanding the Ethics of Generative AI: Established and New Ethical Principles.” Communications of the Association for Information Systems, vol. 56, no. 1, 9 Jan. 2025, <a href="www.researchgate.net/publication/387854870_Understanding_the_Ethics_of_Generative_AI_Established_and_New_Ethical_Principles">www.researchgate.net/publication/387854870_Understanding_the_Ethics_of_Generative_AI_Established_and_New_Ethical_Principles</a>, <a href="https://doi.org/10.17705/1CAIS.05601">https://doi.org/10.17705/1CAIS.05601</a>.</p>
            </section>
        </article>
    </body>
</html>
